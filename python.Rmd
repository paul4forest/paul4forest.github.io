---
title: "Python Commands"
author: "Paul Rougieux"
date: "17 August 2017"
output: 
  html_document: 
    toc: yes
---


# Pip

pypi.org [pip](https://pypi.org/project/pip/):

> "pip is the package installer for Python. You can use pip to install packages
> from the Python Package Index and other indexes."


## Install an old version

For example to install pandas 0.24.2

     python3 -m pip install --user pandas==0.24.2 

or

    pip3 install --user pandas==0.24.2


# Control flow

dotnetperls: [not python](https://www.dotnetperls.com/not-python)


# Editors

## Spyder

I have set the following shortcuts to be similar to RStudio:

* Ctrl+H find and replace dialog
* Ctrl+R run selection or current line
* Ctrl+Shift+C comment/uncomment code block
* F1 inspect current object (i.e. display function and classes documentation)
* F2 go to function definition

# Neural Networks

## Pytorch

Print the size of the output layer

    import torch
    import torch.nn as nn
    x = torch.randn(28,28).view(-1,1,28,28)
    model = nn.Sequential(
          nn.Conv2d(1, 32, (3, 3)),
          nn.ReLU(),
          nn.MaxPool2d((2, 2)),
          nn.Conv2d(32, 64, (3, 3)),
    )
    print(model(x).shape)


# Object types

`type()` displays the type of an object.

    i = 1
    print(type(i))
    # <type 'int'>
    x = 1.2
    print(type(x))
    # <type 'float'>
    t = (1,2)
    print(type(t))
    # <type 'tuple'>
    l = [1,2]
    print(type(l))
    # <type 'list'>

## List

[Remove an element from a list of strings ](https://stackoverflow.com/a/31077838/2641825)

    myList = ['a', 'b', 'c', 'd']
    myList.remove('c')
    myList
    ['a', 'b', 'd']


### List of tuples

[How to flatten a list of tuples](https://stackoverflow.com/questions/10632839/transform-list-of-tuples-into-a-flat-list-or-a-matrix)

    nested_list = [(1, 2, 4), (0, 9)]

Using `reduce`:

    reduce(lambda x,y:x+y, map(list, nested_list))                                                                                                                              
    [1, 2, 4, 0, 9]

Using itertools.chain:

    import itertools
    list(itertools.chain.from_iterable(nested_list))

Using `extend`:
    
    flat_list = []
    for a_tuple in nested_list:
        flat_list.extend(list(a_tuple))                                                                                                                                     
    flat_list
    [1, 2, 4, 0, 9]


## Set

Instances of [set](https://docs.python.org/3/library/stdtypes.html#set)
provide the following operations:


	issubset(other)
	set <= other

	    Test whether every element in the set is in other.

	set < other

	    Test whether the set is a proper subset of other, that is, set <= other and set != other.

	issuperset(other)
	set >= other

	    Test whether every element in other is in the set.

	set > other

	    Test whether the set is a proper superset of other, that is, set >= other and set != other.

	union(*others)
	set | other | ...

	    Return a new set with elements from the set and all others.

	intersection(*others)
	set & other & ...

	    Return a new set with elements common to the set and all others.

	difference(*others)
	set - other - ...

	    Return a new set with elements in the set that are not in the others.

	symmetric_difference(other)
	set ^ other

	    Return a new set with elements in either the set or other but not both.
    

# ipython

Add these options at the ipyhton command line to reload objects automatically while you are coding

    %load_ext autoreload   
    %autoreload 2         


## Debugging in ipython


Once an error occurs at the ipython command line. 
Press `debug` then you can move up the stack trace with:

    `u`

Move down the stack trace with:

    `d` 

Show code context of the error:

    `l` 

Show available variable in the current context:

    `a` 





# Jupyter notebooks


## Install Jupyter

To [install Jupyter](https://jupyter.org/install) notebooks on python3:

    pip3 install jupyter notebook

Then start the notebook server as such:

    jupyter notebook


## Help in a jupyter notebook 

To get help on a function, enter `function_name?` in a cell. 
Quick hep can also be obtained by pressing SHIFT + TAB.

## Call bash from a notebook

Prefix the bash call with an exclamation mark, for example:

    !df -h

In fact the question mark also works from an ipython shell. 
See also 
[Difference between ! and % in Jupyter Notebooks](https://stackoverflow.com/questions/45784499/difference-between-and-in-jupyter-notebooks)

## Download data from a jupyter notebook    

I wrote this csv download function in an 
[SO answer](https://stackoverflow.com/a/57613621/2641825)

    def csv_download_link(df, csv_file_name, delete_prompt=True):
        """Display a download link to load a data frame as csv from within a Jupyter notebook"""
        df.to_csv(csv_file_name, index=False)
        from IPython.display import FileLink
        display(FileLink(csv_file_name))
        if delete_prompt:
            a = input('Press enter to delete the file after you have downloaded it.')
            import os
            os.remove(csv_file_name)

To get a link to a csv file, enter the above function and the code below in a jupyter notebook cell :

    csv_download_link(df, 'df.csv')

## Documentation with Jupyter

[Using jupyter to write documentation](https://hub.packtpub.com/using-jupyter-write-documentation/)

## Table of content in your notebooks

Install [jupyter_contrib_nbextensions](https://github.com/ipython-contrib/jupyter_contrib_nbextensions)

    python3 -m pip install --user jupyter_contrib_nbextensions
    python3 -m jupyter contrib nbextension install --user

Activate the table of content extension:

    python3 -m jupyter nbextension enable toc2/main

There are many other extensions available in this package.
Optionally you can install the jupyter notebook extension configurator (not needed)

    python3 -m pip install --user jupyter_nbextensions_configurator
    jupyter nbextensions_configurator enable --user

This will make a configuration interface available at:

    http://localhost:8888/nbextensions



Using the old Table of Content extension
[jupyter table of content extension](https://github.com/minrk/ipython_extensions#table-of-contents)


    jupyter nbconvert --to markdown mynotebook.ipynb
    jupyter nbconvert --to html mynotebook.ipynb



## Version control the markdown version with git
Convert notebooks to markdown so they are easier to track in git. 

Install https://github.com/mwouts/jupytext

    python3 -m pip install --user jupytext

More commands:

    python3 -m jupyter notebook --generate-config
    vim ~/.jupyter/jupyter_notebook_config.py

Add this line:

    c.NotebookApp.contents_manager_class = "jupytext.TextFileContentsManager"

And also this line if you always want to pair notebooks with their markdown counterparts:

    c.ContentsManager.default_jupytext_formats = "ipynb,md"

More commands:

    python3 -m jupyter nbextension install jupytext --py --user
    python3 -m jupyter nbextension enable  jupytext --py --user

Add syncing to a given notebook:

    # Markdown sync
    jupytext --set-formats ipynb,md --sync ~/repos/example_repos/notebooks/test.ipynb
    # Python sync
    jupytext --set-formats ipynb,py --sync ~/repos/example_repos/notebooks/test.ipynb

# Functions

Functions in python can be defined with 

    def add_one(x):
        return x + 1
    add_one(1)

    # 2

## Call by reference or call by value

When using numpy arrays, python displays a behaviour of call by reference 

    a = np.array([1,2])

    def changeinput(x, scalar):
        x[0] = scalar

    changeinput(a,3)

    a
    # array([3, 2])

This is really weird coming from R, which has a copy-on-modify principle.

The R Language Definition says this (in section 4.3.3 Argument Evaluation)

> "The semantics of invoking a function in R argument are call-by-value. In
> general, supplied arguments behave as if they are local variables initialized
> with the value supplied and the name of the corresponding formal argument.
> Changing the value of a supplied argument within a function will not affect
> the value of the variable in the calling frame. [Emphasis added]"

## Decorators

Decorators are a way to wrap a function around another function. 
It is useful to repeat a pattern of behaviour around a function.

* Data camp [course on decorators](https://www.datacamp.com/community/tutorials/decorators-python)
* Examples [5 use cases for decorators](https://www.oreilly.com/ideas/5-reasons-you-need-to-learn-to-write-python-decorators)

I have used decorators to cache the function output
along a data processing pipeline. 

# Math

[How to do maths in python 3 with operators](https://www.digitalocean.com/community/tutorials/how-to-do-math-in-python-3-with-operators) 

2 to the power of 3

    2**3
    # 8

Floor division

    5//3
    # 1

Modulo

    5%3
    # 2

# Numpy vectors and matrices (arrays)

All examples below are based on the numpy package being imported as np :

    import numpy as np


## Indexing Multi-dimensional arrays and masks

Numpy [array indexing](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)

> "Basic slicing extends Python’s basic concept of slicing to N dimensions. Basic slicing occurs when 
> obj is a slice object (constructed by start:stop:step notation inside of brackets), an integer, or a tuple of slice objects and integers."
> [...]
> The basic slice syntax is i:j:k where i is the starting index, j is the stopping index, and k is the step ($k\neq0$).
> "[...]
> "Advanced indexing always returns a copy of the data (contrast with basic slicing that returns a view)." 
> "Integer array indexing allows selection of arbitrary items in the array based on their N-dimensional index.
> Each integer array represents a number of indexes into that dimension."

    x[0:3,0:2]
    # array([[0.64174957, 0.18540429],
    #        [0.97558697, 0.69314058],
    #        [0.51646795, 0.71055115]])

In this case because every row is selected, it is the same as:

    x[:,0:2]

Examples modified from https://docs.scipy.org/doc/numpy/user/basics.indexing.html

    y = np.arange(35).reshape(5,7)
    print(y[np.array([0,2,4]), np.array([0,1,2])])

    print('With slice 1:3')
    print(y[np.array([0,2,4]),1:3])
    print('is equivalent to')
    print(y[np.array([[0],[2],[4]]),np.array([[1,2]])])
    # This one is the same but transposed, which is weird
    print(y[np.array([[0,2,4]]),np.array([[1],[2]])])
    # Notice the difference with the following
    print(y[np.array([0,2,4]),np.array([1,2,3])])

Masks [masked array](https://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html)
We wish to mark the fourth entry as invalid. The easiest is to create a masked array:

    x = np.array([1, 2, 3, -1, 5])
    mx = np.ma.masked_array(x, mask=[0, 0, 0, 1, 0])
    print(x.sum(), mx.sum())
    # 10 11


## Matrix creation and shapes

Create a vector

    a = np.array([1,2,3])

Create a matrix

    b = np.array([[1,2,3],[5,6,6]])

Shape

    a.shape
    # (3,)
    b.shape
    # (2, 3)

Matrix of zeroes

    np.zeros([2,2])
    #array([[0., 0.],
    #       [0., 0.]])

Create a matrix with an additional dimension 

    np.zeros(b.shape + (2,))
    array([[[0., 0.],
            [0., 0.],
            [0., 0.]],

           [[0., 0.],
            [0., 0.],
            [0., 0.]]])

Transpose

    b.transpose()
    # array([[1, 5],
    #        [2, 6],
    #        [3, 6]])
    c = b.transpose()

Math functions in numpy:

    np.cos()
    np.sin()
    np.tan()
    np.exp()

min and max

    x = np.array([1,2,3,4,5,-7,10,-8])
    x.max()
    # 10
    x.min()
    # -8

## Matrix multiplication

Matrix multiplication [matmul](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html)

    np.matmul(a,c)
    # array([14, 35])

    # Can also be written as
    a @ c
    # array([14, 35])

Otherwise the multiplication symbol implements an element wise multiplication, also called the

[Hadamard product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)).
It only works on 2 matrices of same dimensions. 
Element-wise multiplication is used for example in convolution kernels. 

    b * b
    # array([[ 1,  4,  9],
    #        [25, 36, 36]])

So here is again an example showing the difference between

    m = np.array([[0,1],[2,3]])

Element wise multiplication :

    m * m 
    # array([[0, 1],
    #        [4, 9]])

Matrix multiplication :

    m @ m
    # array([[ 2,  3],
    #        [ 6, 11]])

Linear algebra with numpy.linalg
For example the norm of a matrix or vector:

    np.linalg.norm(x)
    # 16.3707055437449
    np.linalg.norm(np.array([3,4]))
    # 5.0
    np.linalg.norm(a)
    # 3.7416573867739413

Norm of the matrix for the regularization parameter in a machine learning model

    bli = np.array([[1, 1, 0.0, 0.0, 0.0],
                    [0.0, 0.0, 0.0, 0.0, 0.0],
                    [0.0, 0.0, 0.0, 0.0, 0.0],
                    [0.0, 0.0, 0.0, 0.0, 0.0],
                    [0.0, 0.0, 0.0, 0.0, 0.0],
                    [0.0, 0.0, 0.0, 0.0, 0.0],
                    [0.0, 1, 0.0, 0.0, 0.0]])
    sum(np.linalg.norm(bli, axis=0)**2) 3.0000000000000004
    sum(np.linalg.norm(bli, axis=1)**2) 3.0000000000000004
    np.linalg.norm(bli)**2 2.9999999999999996

Append vs concatenate

    x = np.array([1,2])
    print(np.append(x,x))
    # [1 2 1 2]
    print(np.concatenate((x,x),axis=None))
    a = np.array([[1, 2], [3, 4]])
    b = np.array([[5, 6]])
    print(np.concatenate((a, b), axis=0))
    print(np.concatenate((a, b.T), axis=1))
    print(np.concatenate((a, b), axis=None))

## Random vector or matrices

    x = np.random.random([3,4])
    x
    # array([[0.64174957, 0.18540429, 0.7045183 , 0.44623567],
    #        [0.97558697, 0.69314058, 0.32469324, 0.82612627],
    #        [0.51646795, 0.71055115, 0.74864751, 0.2142459 ]])


Random choice, with a given probability
Choose zero with probability 0.1 and one with probability 0.9.

    for i in range(10):
        print(np.random.choice(2, p=[0.1, 0.9]))
        
    print(np.random.choice(2, 10, p=[0.1, 0.9]))
    print(np.random.choice(2, (10,10), p=[0.1, 0.9]))

    [[1 1 1 1 1 1 1 1 1 0]
     [1 1 1 1 1 1 1 1 1 1]
     [1 1 1 1 1 1 1 1 1 0]
     [1 1 1 1 1 1 1 1 1 1]
     [1 1 1 1 1 1 1 0 1 1]
     [1 1 1 0 1 1 1 1 1 1]
     [1 1 0 1 1 1 1 1 0 1]
     [1 1 1 1 1 1 1 1 1 1]
     [1 1 1 1 1 1 0 1 1 0]
     [1 1 1 1 1 1 1 1 1 1]]

Error if probabilities do not sum up to one

    print(np.random.choice(2, p=[0.1, 0.8]))

    # ---------------------------------------------------------------------------
    # ValueError                                Traceback (most recent call last)
    # <ipython-input-31-8a8665287968> in <module>
    # ----> 1 print(np.random.choice(2, p=[0.1, 0.8]))

    # mtrand.pyx in numpy.random.mtrand.RandomState.choice()

    # ValueError: probabilities do not sum to 1


# Objects

## Inheritance and composition

Example 

    ###############################################################################
    class Vehicle(object):

        def __init__(self, color, speed_max, garage=None):
            # Default attributes #
            self.color = color
            self.speed_max = speed_max
            self.garage = garage

        def paint(self, new_color):
            # Default attributes #
            self.color = new_color

        def go_back_home(self, new_color):
            # Default attributes #
            self.position = self.go_to(self.parent.location)

    ###############################################################################
    class Car(Vehicle):

        def open_door(self):
            pass

    ###############################################################################
    class Boat(Vehicle):

        def open_balast(self):
            pass

    ###############################################################################
    class Garage(object):

        def __init__(self, all_vehicles):
            self.all_vehicles = all_vehicles

        def mass_paint(self, new_color):
            # Default attributes #
            for v in self.all_vehicles: v.paint(new_color)

        def build_car(self, color):
            new_car = Car(color, 90, self)
            self.all_vehicles.append(new_car)
            return new_car

        @property
        def location(self):
            return '10, 18'

    ###############################################################################
    ###############################################################################
    ###############################################################################
    honda = Car('bleu', 60)
    gorgeoote = Boat('rouge', 30)
    honda.paint('purple')

    mike = Garage([honda, gorgeoote])

    mike.mass_paint()

    sport_car = mike.build_car('rouge')


# Pandas data frames

## Creating a pandas data frame

You can create a data frame by passing a dictionary :

    import pandas 
    pandas.DataFrame({'a':range(0,3),'b':range(3,6)})
           a  b
        0  0  3
        1  1  4
        2  2  5


## Joining and merging

Stackoverflow [Pandas mergin](https://stackoverflow.com/questions/53645882/pandas-merging-101/53645883#53645883)


## Reshaping

[The Pandas user guide on reshaping](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping-by-melt) 
gives several example using `melt` (easier to rename the  “variable” and “value” columns) 
or `stack` (designed to work together with MultiIndex objects).


## Replacement

[Pyton pandas equivalent for replace](https://stackoverflow.com/questions/12152716/python-pandas-equivalent-for-replace)

    import pandas
    s = pandas.Series(["ape", "monkey", "seagull"])
    s.replace(["ape", "monkey"], ["lion", "panda"])
    s.replace("a", "x", regex=True)
    `s.replace({"ape": "lion", "monkey": "panda"})`
    pandas.Series(["bla", "bla"]).replace("a","i",regex=True)


## Selection with loc, iloc, query and isin

 * blog [Select pandas data frame rows and columns using iloc and loc](https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/)


### loc

`.loc` is primarily label based, but may also be used with a boolean array.

I copied the examples below from the pandas **loc** documentation at:
[pandas.DataFrame.loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html)

Create an example data frame

    import pandas
    df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                          index=['cobra', 'viper', 'sidewinder'],
                          columns=['max_speed', 'shield'])

List of index labels

    In :  df.loc[['viper', 'sidewinder']]
    Out:
                        max_speed  shield
            viper               4       5
            sidewinder          7       8

Conditional that returns a boolean Series

    In :  df.loc[df['shield'] > 6]
    Out:
                         max_speed  shield
             sidewinder          7       8

Select rows that are not in ['cobra','viper'] 
Based on a [SO answer use isin on the index](https://stackoverflow.com/a/29140194/2641825):

    In : df.index.isin(['cobra','viper'])
    Out: array([ True,  True, False])

    In : df.loc[~df.index.isin(['cobra','viper'])]
    Out: 
                max_speed  shield
    sidewinder          7       8

Slice with labels for row and labels for columns.

    In :  df.loc['cobra':'viper', 'max_speed':'shield']
    Out:
                   max_speed  shield
            cobra          1       2
            viper          4       5

Set value for all items matching the list of labels

    In : df.loc[['viper', 'sidewinder'], ['shield']] = 50

    In : df
    Out:
                        max_speed  shield
            cobra               1       2
            viper               4      50
            sidewinder          7      50

Another example using integers for the index

    In : df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                               index=[7, 8, 9],
                               columns=['max_speed', 'shield'])

Slice with integer labels for rows. Note that both the start and stop of the slice are included.

    In :  df.loc[8:9]
    Out:
          max_speed  shield
       8          4       5
       9          7       8

### iloc 

[.iloc](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-integer)
is primarily integer position based (from 0 to length -1 of the axis), but may also be used with a boolean array.

Create a sample data frame:

    In : example = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},
                    {'a': 100, 'b': 200, 'c': 300, 'd': 400},
                    {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]
          df = pandas.DataFrame(example)

    In : df
    Out: 
                a     b     c     d
          0     1     2     3     4
          1   100   200   300   400
          2  1000  2000  3000  4000

Index with a slice object. Note that it doesn't include the upper bound.

    In :  df.iloc[0:2]
    Out: 
              a    b    c    d
         0    1    2    3    4
         1  100  200  300  400

With lists of integers.

    In : df.iloc[[0, 2], [1, 3]]
    Out: 
                b     d
          0     2     4
          2  2000  4000

With slice objects.

    In : df.iloc[1:3, 0:3]
    Out: 
                a     b     c
          1   100   200   300
          2  1000  2000  3000

With a boolean array whose length matches the columns.

    In : df.iloc[:, [True, False, True, False]]
    Out: 
                a     c
          0     1     3
          1   100   300
          2  1000  3000
### Query

Query the columns of a Data Frame with a boolean expression.

    df = pandas.DataFrame({'A': range(1, 6),
                           'B': range(10, 0, -2),
                           'C': range(10, 5, -1)})
    df.query("A > B")

    A  B  C
    5  2  6

Query using a variable

    limit = 3
    df.query("A > @limit")

    A  B  C
    4  4  7
    5  2  6


### isin

[Use alist of values to select rows](https://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe)

    df = pandas.DataFrame({'A': [5,6,3,4], 'B': [1,2,3,5]})
    df[df['A'].isin([3, 6])]
    df.loc[df['A'].isin([3, 6])]
    df.query("A in [3,6]")

## String operations

Concatenate all values in a character vector:

    df['A'].str.cat()

Replace elements in a character vector:

    df['A'].replace('a','b',regex=True)

## Difference between 2 data frames

* [Find difference between two data frames](https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames)
* [Diff of 2 data frames](https://stackoverflow.com/questions/36891977/pandas-diff-of-two-dataframes/36893773)

Two methods
Using `merge`:

    merged = df1.merge(df2, indicator=True, how='outer')
    merged[merged['_merge'] == 'right_only']

Using `drop_duplicates`

    newdf=pd.concat[df1,df2].drop_duplicates(keep=False)


# Plot

## Matplotlib

All matplotlib examples require the following imports:

    from matplotlib import pyplot
    pyplot.style.use('seaborn-whitegrid')
    import numpy as np

Simple line plot changing the figure size and the axes limit with pyplot

    pyplot.rcParams['figure.figsize'] = [10, 10]
    fig = pyplot.figure()
    ax = pyplot.axes()
    x = np.linspace(-1.5, 1.5, 1000)
    ax.plot(x, 1-3*x)
    ax.set_xlim(-6, 6)
    ax.set_ylim(-6, 6)

Scatter plot, using a colour variable and the 'jet' colour map.

    Y = np.array([1,-1,-1, 1])
    X = np.array([
            [-1, -1],
            [ 1, -1],
            [-1,  1],
            [ 1,  1]])
    fig = pyplot.figure()
    ax = pyplot.axes()
    ax.scatter(X[:,0], X[:,1],c=Y, cmap='jet')

Use another [colour map](https://matplotlib.org/examples/color/colormaps_reference.html)

    ax.scatter(X[:,0], X[:,1],c=Y, cmap='Spectral')

Plot the probability density function of the 
[normal distribution](https://en.wikipedia.org/wiki/Normal_distribution). 

$$f(x)=\frac{1}{\sigma{\sqrt {2\pi }}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}$$

with various sigma and mu values displayed in the legend.

    fig = pyplot.figure()
    ax = pyplot.axes()
    x = np.linspace(-5, 5, 1000)
    def pdensitynormal(x,sigma_squared,mu):
        sigma = np.sqrt(sigma_squared)
        return 1/(sigma*np.sqrt(2*np.math.pi))*np.exp(-1/2*((x-mu)/sigma)**2)
    ax.plot(x, pdensitynormal(x,0.2,0), label="$\sigma^2=0.2, \mu=0$")
    ax.plot(x, pdensitynormal(x,1,0), label="$\sigma^2=1, \mu=0$")
    ax.plot(x, pdensitynormal(x,5,0), label="$\sigma^2=5, \mu=0$")
    ax.plot(x, pdensitynormal(x,0.5,-2), label="$\sigma^2=0.5, \mu=-2$")
    ax.legend(loc="upper right")

3D line, contour plot and scatter plot

    from mpl_toolkits import mplot3d # Required for 3d plots
    fig = pyplot.figure()
    ax = pyplot.axes(projection='3d')
    # Data for a three-dimensional line
    xline = np.linspace(-10, 10, 1000)
    yline = np.linspace(-10, 10, 1000)
    # Just a line
    zline = xline**2 + yline**2
    ax.plot3D(xline, yline, zline, 'gray')
    # A mesh grid
    X, Y = np.meshgrid(xline, yline)
    Z = X**2 + Y**2
    ax.contour3D(X, Y, Z, 50, cmap='binary')
    # Scatter points
    ax.scatter(1,2,3)

See how the `np.meshgridi` objects interact with each other.
Note this nested loop is not the optimal way to compute.
Better to use X**2 + Y**2 directly as above.

    for i in range(Z.shape[0]):
        for j in range(Z.shape[1]):
            vector = np.array([X[i,j],Y[i,j]])
                Z[i,j] = np.linalg.norm(vector)**2
    fig = pyplot.figure()
    ax = pyplot.axes(projection='3d')
    ax.contour3D(X, Y, Z, 50, cmap='binary')

## Seaborn

All seaborn examples below require the following imports and datasets:

    import seaborn
    iris = seaborn.load_dataset("iris")
    tips = seaborn.load_dataset("tips") 
    from matplotlib import pyplot

### Axes limit

Set limits on the one axis in a Seaborn plot:

    p = seaborn.scatterplot('petal_length','petal_width','species',data=iris)
    p.set(ylim=(-2,None))


In Seaborn facet grid.
[How to set xlim and ylim in seaborn facet grid](https://stackoverflow.com/a/25213614/2641825)

    g = seaborn.FacetGrid(tips, col="time", row="smoker")
    g = g.map(pyplot.hist, "total_bill")
    g.set(ylim=(0, None)) 

### Grid plot


    g = seaborn.FacetGrid(iris, col="species")
    iris['species'] = iris['species'].astype('category')
    g.map(seaborn.scatterplot,'petal_length','petal_width','species')

Notice that if you don't change the color to a categorical variable, it will not vary across the species. 
I reported [this issue](https://github.com/mwaskom/seaborn/issues/2028).

### Title

Use `set_title` to add a title:

    (seaborn
     .scatterplot(x="total_bill", y="tip", data=tips)
     .set_title('Progression of tips along the bill amount')
    )

Set a common title for grid plots

    g = seaborn.FacetGrid(tips, col="time", row="smoker")
    g = g.map(pyplot.hist, "total_bill")
    g.fig.suptitle('I don't smoke and I don't tip.')

In case the title is overwritten on the subplots, you might need to use 
[fig.subplot_adjust()](https://stackoverflow.com/a/28650623/2641825) 
as such:

    g.fig.subplots_adjust(top=.95)

### Figure size

`set_figwidth` and `set_figheight` work well for grid objects. 

    g = seaborn.FacetGrid(tips, col="time", row="smoker")
    g = g.map(pyplot.hist, "total_bill")
    g.fig.set_figwidth(10)
    g.fig.set_figheight(10) 

Mentioned as a comment under [this answer](https://stackoverflow.com/a/56970556/2641825)

# R and python

See also the section above on pandas data frame / comparison with R. 

[Migrating from R to python](https://jrvcomputing.wordpress.com/2016/11/14/migrating-from-r-to-python/)
Python is a full fledge programming language but it is missing statistical and plotting libraries.
Vectors are an after thought in python most functionality can be reproduced using operator overloading,
but some functionality looks clumsy. 

## Pandas comparison with R

 * pandas.pydata.org [Comparison with R](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html)
 * [Tydiverse style pandas](https://stmorse.github.io/journal/tidyverse-style-pandas.html) 

> "Tidyverse allows a mix of quoted and unquoted references to variable names. In my (in)experience, the convenience this brings is accompanied by equal consternation. It seems to me a lot of the problems solved by tidyeval would not exist if all variables were quoted all the time, as in pandas, but there are likely deeper truths I’m missing here…"

R data frame to be used for examples:

    df = data.frame(x = 1:3, y = c('a','b','c'), stringsAsFactors = FALSE)

Pandas data frame to be used for examples:

    `df = pandas.DataFrame({'x' : [1,2,3], 'y' : ['a','b','c']})  `

|Base R                     |pandas                       |SO questions      |
|---------------------------|-----------------------------|------------------|
|gsub                       |replace(regex=True)          |[gsub in pandas]  |
|`df[df$y %in% c('a','b'),]`|`df[df['y'].isin(['a','b'])]`|[list of values to select a row]|
|length(df) and dim(df)     |df.shape                     |[row count of a data frame]|
|rbind                      |pandas.concat                |[Pandas version of rbind]|
|dput(df)                   |df.to_dict()                 |[Print pandas data frame for reproducible example]|
|seq(1:5)                   |np.array(range(0,5))         |[numpy function to generate sequences]|

[gsub in pandas]: https://stackoverflow.com/questions/21834293/equivalent-of-gsub-for-pandas-series-dataframe/56547104?noredirect=1#comment99677847_56547104
[list of values to select a row]: https://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe
[row count of a data frame]: https://stackoverflow.com/questions/15943769/how-do-i-get-the-row-count-of-a-pandas-dataframe
[Pandas version of rbind]: https://stackoverflow.com/questions/14988480/pandas-version-of-rbind
[Print pandas data frame for reproducible example]: https://stackoverflow.com/questions/47450931/print-pandas-data-frame-for-reproducible-example-equivalent-to-dput-in-r
[numpy function to generate sequences]: https://stackoverflow.com/a/60753578/2641825

The mapping of tidyverse to pandas is:

|tidyverse                |pandas                        | SO questions    |
|-------------------------|----------------------------- |-----------------|
|mutate                   |assign                        |                 |
|select                   |filter                        |                 |
|df %>% select(-a,-b)     |df.drop(columns=['a', 'b'])   |                 |
|rename                   |df.rename(columns={'a':'new'})|                 |
|filter                   |query                         |                 |
|arrange                  |sort_values                   |                 |
|group_by                 |groupby                       |                 |
|summarize                |agg                           |                 |
|pivot_longer             |[melt]                        |                 |
|pivot_wider              |[pivot]                       |                 |
|unnest                   |[explode]                     |[unnest in pandas][so_unnest]|

[melt]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html
[pivot]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html
[explode]: https://pandas.pydata.org/pandas-docs/version/0.25/reference/api/pandas.DataFrame.explode.html
[so_unnest]: https://stackoverflow.com/a/53218939/2641825

Methods to use inside the .groupby().agg() method:

* `sum`
* `count`
* `mean`
* `', '.join` [to get a union of strings](https://stackoverflow.com/questions/17841149/pandas-groupby-how-to-get-a-union-of-strings)


# String 

[SO answer ](https://stackoverflow.com/questions/25675943/how-can-i-concatenate-str-and-int-objects) 
providing various ways to concatenate python strings.

## String formatting

[How to print number with commas as thousands separators?](https://stackoverflow.com/a/10742904/2641825)

    f'{1e6:,}' 

# Statistics

## Scaling

[Feature scaling with scikit learn](http://benalexkeen.com/feature-scaling-with-scikit-learn/)

 * StandardScaler
 * MinMaxScaler
 * RobustScaler
 * Normalizer

# Style guide and linter

[Black](https://github.com/psf/black)
"the uncompromising Python code formater"




# Unit tests

See [python markdown unit tests](https://github.com/okken/markdown.py/blob/master/test_markdown_unittest.py)

## pytest
Numpy moved from nose to pytest in their, as explained in their
[testing guidelines](https://docs.scipy.org/doc/numpy/reference/testing.html):

> "Until the 1.15 release, NumPy used the nose testing framework, it now uses the pytest framework. The older framework is still maintained in order to support downstream projects that use the old numpy framework, but all tests for NumPy should use pytest." 

Save this function in a file names test_numpy.py

    def test_numpy_closeness():
        assert [1,2] == [1,2]
        assert (np.array([1,2]) == np.array([1,2])).all()
        np.testing.assert_allclose(np.array([1,2]),np.array([1,3]))

Save the file to test_nn.py

    import neural_nets as nn
    import numpy as np

    def test_rectified_linear_unit():
        x = np.array([[1,0],
                      [-1,-3]])
        expected = np.array([[1,0],
                             [0,0]])
        provided = nn.rectified_linear_unit(x)
        assert np.allclose(expected, provided), "test failed"

Execute the test suite from bash with py.test as follows:

    cd ~/rp/course_machine_learning/projects/project_2_3_mnist/part2-nn
    py.test

Test pandas data frame with

    assert_frame_equal
    assert_series_equal # tricky to use


# Web Frameworks

[Flask vs. Django](asynchrosnus://www.codementor.io/garethdwyer/flask-vs-django-why-flask-might-be-better-4xs7mdf8v)

Note: [Flask Evolution into Quart](http://pgjones.gitlab.io/quart/flask_evolution.html#flask-evolution) 
to support 
[asyncio](http://pgjones.gitlab.io/quart/asyncio.html#asyncio) 
This last link contains a nice, simple example of 
how asyncio works with a simulated delay to fetch a web page.


# Media

Podcast [talk python to me](https://talkpython.fm/)
 * [Data science year in review](https://talkpython.fm/episodes/show/193/data-science-year-in-review-2018-edition)

## Blogs
* [Things I Learnt The Hard Way (in 30 Years of Software Development)](https://blog.juliobiason.me/thoughts/things-i-learnt-the-hard-way/)
* [I do not use a debugger](https://lemire.me/blog/2016/06/21/i-do-not-use-a-debugger/)
    >"“Debuggers don’t remove bugs. They only show them in slow motion.”
    [Linus Toarvald doesn't use a debugger](https://lwn.net/2000/0914/a/lt-debugger.php3)


